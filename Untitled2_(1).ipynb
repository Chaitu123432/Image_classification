{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Classification**"
      ],
      "metadata": {
        "id": "QtAlUKso8i40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Cifar-100 dataset to find performances of Image classification models such as VGG16, InceptionV3 and RESNET50 on large datasets with such large number of classes.\n",
        "\n",
        "Trying to design a efficient algorithm to work with Cifar-100."
      ],
      "metadata": {
        "id": "azI52wAz8rek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "BVO0t-5R9s1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7yRrMVfv-dsJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Dense, Flatten,AveragePooling2D,UpSampling2D\n",
        "from keras import Sequential\n",
        "from keras.models import Model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "y8jhbo9b-f2m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset**\n",
        "\n",
        "We can use the readily available dataset."
      ],
      "metadata": {
        "id": "tei7pw1092nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wWjw9GZ-i4p",
        "outputId": "198e8a3b-d45e-4479-c310-f1dd10dce45a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "r-Kn5-81-FMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "y59hJHOx-lLn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_processed = preprocess_input(x_train)\n",
        "x_test_processed = preprocess_input(x_test)"
      ],
      "metadata": {
        "id": "etxmfWRV_gSG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RESNET50 model**"
      ],
      "metadata": {
        "id": "0bgWZzlu_qrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = ResNet50(include_top = False,weights = 'imagenet',input_shape = (32,32,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrF6lP4KSHv",
        "outputId": "3b7c3ae2-873c-4ab8-986d-c4fb4f6d2702"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(resnet_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(100, activation='softmax')(x)\n",
        "resnet_model=Model(inputs=resnet_model.input,outputs=output_layer)"
      ],
      "metadata": {
        "id": "_SQ8s2HDMDDw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SBkrKl2-LrrF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u3i_FrSI_bgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.fit(x_train, y_train, epochs=5,batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM2uGXTcL4dG",
        "outputId": "17fa3a50-d6f7-4042-f364-c3ff69a89441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 18/782 [..............................] - ETA: 1:03:44 - loss: 4.1502 - accuracy: 0.0668"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of RESNET50 after 5 epochs is"
      ],
      "metadata": {
        "id": "Z1f8N85nA5V4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InceptionV3 Model**"
      ],
      "metadata": {
        "id": "iRGRzqTrAEsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionv3_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
      ],
      "metadata": {
        "id": "aS7uZWQ9NnzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionv3_model = Sequential()\n",
        "inceptionv3_model.add(UpSampling2D((2,2)))              ## UpSampling increase the row and column of the data.Sometimes if we have less data so we can try to increase the data in this way.\n",
        "inceptionv3_model.add(UpSampling2D((2,2)))\n",
        "inceptionv3_model.add(UpSampling2D((2,2)))\n",
        "inceptionv3_model.add(inceptionv3_base)                             ## conv_base is the inception network.We are keeping it here.\n",
        "inceptionv3_model.add(Flatten())\n",
        "inceptionv3_model.add(Dense(128, activation='relu' ))\n",
        "inceptionv3_model.add(Dropout(0.5))\n",
        "inceptionv3_model.add(BatchNormalization())\n",
        "inceptionv3_model.add(Dense(64, activation='relu'))\n",
        "inceptionv3_model.add(Dropout(0.5))\n",
        "inceptionv3_model.add(BatchNormalization())\n",
        "inceptionv3_model.add(Dense(100, activation='softmax'))\n",
        "inceptionv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "inceptionv3_model.fit(x_train_processed, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "w6DxkrcxRwXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of InceptionV3 after 5 epochs is"
      ],
      "metadata": {
        "id": "sSR2aiPKBTS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG16 Model**"
      ],
      "metadata": {
        "id": "a2tctf6BBW_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #VGG-16 model\n",
        "\n",
        "\n",
        "vgg16_model = Sequential()\n",
        "\n",
        "vgg16_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "vgg16_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Flatten())\n",
        "vgg16_model.add(Dense(4096, activation='relu'))\n",
        "vgg16_model.add(Dropout(0.5))\n",
        "vgg16_model.add(Dense(4096, activation='relu'))\n",
        "vgg16_model.add(Dropout(0.5))\n",
        "vgg16_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "vgg16_model.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y_yjj_gB6fcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg16_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(100, activation='softmax')(x)\n",
        "vgg16_model=Model(inputs=vgg16_model.input,outputs=output_layer)"
      ],
      "metadata": {
        "id": "gGJEy3nlBsa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16_model.layers:\n",
        "            layer.trainable = True\n",
        "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MLPB91RW8g2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.fit(x_train_processed, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "4fH_gbz18n3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of VGG16 after 5 epochs is"
      ],
      "metadata": {
        "id": "XVMbs9ZtBq7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Making Changes to VGG16 Model**\n",
        "\n",
        "\n",
        "\n",
        "This would help us to make results more accurate as the dataset is very large.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3b-3xAanJIpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', input_shape=(32,32,3),activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0RwJX8ti-pln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "UVrHs15L-n2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "id": "GR7ILdma-0xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.random.choice(x_test.shape[0], 10)\n",
        "x_pred = x_test[indices]\n",
        "y_true = y_test[indices]"
      ],
      "metadata": {
        "id": "tjF7qydj-5xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(x_pred)\n",
        "y_pred_class = np.argmax(y_pred_prob, axis=-1)"
      ],
      "metadata": {
        "id": "IxGPP5iD-8OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(x_pred[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('True: %d\\nPred: %d' % (np.argmax(y_true[i]), y_pred_class[i]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6mlM8KI--wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Insights**"
      ],
      "metadata": {
        "id": "xawy637NCIh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Complex Models such as VGG16, InceptionV3, RESNET50 lead to less accurate predictions. Model could be simpler to be better."
      ],
      "metadata": {
        "id": "JFAAcZZ28hSc"
      }
    }
  ]
}