{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Classification**"
      ],
      "metadata": {
        "id": "QtAlUKso8i40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Cifar-100 dataset to find performances of Image classification models such as VGG16, InceptionV3 and RESNET50 on large datasets with such large number of classes.\n",
        "\n",
        "Trying to design a efficient algorithm to work with Cifar-100."
      ],
      "metadata": {
        "id": "azI52wAz8rek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "BVO0t-5R9s1c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7yRrMVfv-dsJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Dense, Flatten,AveragePooling2D,UpSampling2D\n",
        "from keras import Sequential\n",
        "from keras.models import Model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import preprocess_input"
      ],
      "metadata": {
        "id": "y8jhbo9b-f2m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset**\n",
        "\n",
        "We can use the readily available dataset."
      ],
      "metadata": {
        "id": "tei7pw1092nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wWjw9GZ-i4p",
        "outputId": "a8c6a7b7-272b-4f4b-baf3-386c3e5b4517"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "r-Kn5-81-FMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "y59hJHOx-lLn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_processed = preprocess_input(x_train)\n",
        "x_test_processed = preprocess_input(x_test)"
      ],
      "metadata": {
        "id": "etxmfWRV_gSG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RESNET50 model**"
      ],
      "metadata": {
        "id": "0bgWZzlu_qrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = ResNet50(include_top = False,weights = 'imagenet',input_shape = (32,32,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrF6lP4KSHv",
        "outputId": "f97aa380-a8ae-4f52-a57e-4937fda72ad3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(resnet_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(100, activation='softmax')(x)\n",
        "resnet_model=Model(inputs=resnet_model.input,outputs=output_layer)"
      ],
      "metadata": {
        "id": "_SQ8s2HDMDDw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SBkrKl2-LrrF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u3i_FrSI_bgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.fit(x_train, y_train, epochs=5,batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM2uGXTcL4dG",
        "outputId": "b648a1c4-5871-46eb-a455-61ac373a9c4a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 84s 56ms/step - loss: 4.3993 - accuracy: 0.0348 - val_loss: 6.2420 - val_accuracy: 0.0093\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 3.9798 - accuracy: 0.0776 - val_loss: 4.6068 - val_accuracy: 0.0100\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 3.7190 - accuracy: 0.1165 - val_loss: 4.6072 - val_accuracy: 0.0100\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 3.5968 - accuracy: 0.1351 - val_loss: 250.8866 - val_accuracy: 0.0100\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 3.3630 - accuracy: 0.1796 - val_loss: 284.6279 - val_accuracy: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e80d29f3ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of RESNET50 after 5 epochs is 17%\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1f8N85nA5V4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InceptionV3 Model**"
      ],
      "metadata": {
        "id": "iRGRzqTrAEsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionv3_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
      ],
      "metadata": {
        "id": "aS7uZWQ9NnzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ee686d-7349-4c64-9698-f9d0ae58160c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionv3_model = Sequential()\n",
        "inceptionv3_model.add(UpSampling2D((2,2)))\n",
        "inceptionv3_model.add(UpSampling2D((2,2)))\n",
        "inceptionv3_model.add(UpSampling2D((2,2)))\n",
        "inceptionv3_model.add(inceptionv3_base)\n",
        "inceptionv3_model.add(Flatten())\n",
        "inceptionv3_model.add(Dense(64, activation='relu'))\n",
        "inceptionv3_model.add(Dropout(0.5))\n",
        "inceptionv3_model.add(BatchNormalization())\n",
        "inceptionv3_model.add(Dense(100, activation='softmax'))\n",
        "inceptionv3_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "inceptionv3_model.fit(x_train_processed, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "w6DxkrcxRwXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd734d77-d044-4926-9d7b-4b908cdb93a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 533s 617ms/step - loss: 4.4888 - accuracy: 0.0250 - val_loss: 25.0986 - val_accuracy: 0.0100\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 478s 612ms/step - loss: 4.0846 - accuracy: 0.0547 - val_loss: 58.5645 - val_accuracy: 0.0100\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 496s 635ms/step - loss: 3.6892 - accuracy: 0.1019 - val_loss: 46.2092 - val_accuracy: 0.0100\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 480s 613ms/step - loss: 3.3079 - accuracy: 0.1574 - val_loss: 53.2499 - val_accuracy: 0.0100\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 497s 635ms/step - loss: 3.0116 - accuracy: 0.2104 - val_loss: 26.6745 - val_accuracy: 0.0101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b28540d8880>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of InceptionV3 after 5 epochs is 21%"
      ],
      "metadata": {
        "id": "sSR2aiPKBTS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG16 Model**"
      ],
      "metadata": {
        "id": "a2tctf6BBW_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #VGG-16 model\n",
        "\n",
        "\n",
        "vgg16_model = Sequential()\n",
        "\n",
        "vgg16_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "vgg16_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "vgg16_model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "vgg16_model.add(Flatten())\n",
        "vgg16_model.add(Dense(4096, activation='relu'))\n",
        "vgg16_model.add(Dropout(0.5))\n",
        "vgg16_model.add(Dense(4096, activation='relu'))\n",
        "vgg16_model.add(Dropout(0.5))\n",
        "vgg16_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "vgg16_model.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y_yjj_gB6fcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459f0fd9-af32-42a5-b70a-54426b5f749d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_94 (Conv2D)          (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 4, 4, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 2, 2, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 1, 1, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 12291     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33609539 (128.21 MB)\n",
            "Trainable params: 33609539 (128.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg16_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(100, activation='softmax')(x)\n",
        "vgg16_model=Model(inputs=vgg16_model.input,outputs=output_layer)"
      ],
      "metadata": {
        "id": "gGJEy3nlBsa1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16_model.layers:\n",
        "            layer.trainable = True\n",
        "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MLPB91RW8g2h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.fit(x_train_processed, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "4fH_gbz18n3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281d65ab-6418-4fdd-ffa7-4e42854f8932"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 47s 45ms/step - loss: 4.6084 - accuracy: 0.0090 - val_loss: 4.6055 - val_accuracy: 0.0100\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 34s 43ms/step - loss: 4.6062 - accuracy: 0.0089 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 4.6058 - accuracy: 0.0086 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 4.6058 - accuracy: 0.0093 - val_loss: 4.6052 - val_accuracy: 0.0100\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 34s 43ms/step - loss: 4.6058 - accuracy: 0.0091 - val_loss: 4.6052 - val_accuracy: 0.0100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b288cd9a080>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of VGG16 after 5 epochs is 0.9%"
      ],
      "metadata": {
        "id": "XVMbs9ZtBq7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Making Changes to VGG16 Model**\n",
        "\n",
        "\n",
        "\n",
        "This would help us to make results more accurate as the dataset is very large.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3b-3xAanJIpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', input_shape=(32,32,3),activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(AveragePooling2D(2,2))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0RwJX8ti-pln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b4d545-e04b-4912-e6c2-23c2fae93cd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_107 (Conv2D)         (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_95 (Ba  (None, 32, 32, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_96 (Ba  (None, 32, 32, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_9 (Avera  (None, 16, 16, 32)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_97 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_98 (Ba  (None, 16, 16, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " average_pooling2d_10 (Aver  (None, 8, 8, 64)          0         \n",
            " agePooling2D)                                                   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_99 (Ba  (None, 8, 8, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_112 (Conv2D)         (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_100 (B  (None, 8, 8, 128)         512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " average_pooling2d_11 (Aver  (None, 4, 4, 128)         0         \n",
            " agePooling2D)                                                   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               204900    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 493700 (1.88 MB)\n",
            "Trainable params: 492804 (1.88 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "UVrHs15L-n2G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "id": "GR7ILdma-0xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a7189f-d5d7-41b0-dc3c-cfe155e5b8ee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 19s 9ms/step - loss: 4.0654 - accuracy: 0.0969 - val_loss: 69.9640 - val_accuracy: 0.0101\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 3.3479 - accuracy: 0.2034 - val_loss: 20.0198 - val_accuracy: 0.0114\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 2.9722 - accuracy: 0.2781 - val_loss: 46.8270 - val_accuracy: 0.0100\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 2.6608 - accuracy: 0.3358 - val_loss: 42.3737 - val_accuracy: 0.0100\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 2.4358 - accuracy: 0.3808 - val_loss: 9.0040 - val_accuracy: 0.0161\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b2854542800>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of Modified VGG16 after 5 epochs is 38%"
      ],
      "metadata": {
        "id": "xSfe1zzKqHDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.random.choice(x_test.shape[0], 10)\n",
        "x_pred = x_test[indices]\n",
        "y_true = y_test[indices]"
      ],
      "metadata": {
        "id": "tjF7qydj-5xy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(x_pred)\n",
        "y_pred_class = np.argmax(y_pred_prob, axis=-1)"
      ],
      "metadata": {
        "id": "IxGPP5iD-8OC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc74a04-723d-482b-a9f5-f3d293df25e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 570ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(x_pred[i], cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('True: %d\\nPred: %d' % (np.argmax(y_true[i]), y_pred_class[i]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6mlM8KI--wn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "0cbd0e03-0113-4009-a50f-d8486b1ac15a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Insights**"
      ],
      "metadata": {
        "id": "xawy637NCIh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Complex Models such as VGG16, InceptionV3, RESNET50 lead to less accurate predictions. Model could be simpler to be better."
      ],
      "metadata": {
        "id": "JFAAcZZ28hSc"
      }
    }
  ]
}